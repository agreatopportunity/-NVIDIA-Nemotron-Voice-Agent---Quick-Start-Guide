<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>NEMOTRON AI - Neural Voice Assistant</title>
    
    <link rel="apple-touch-icon" sizes="180x180" href="/static/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/static/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/static/favicon-16x16.png">
    <link rel="manifest" href="/static/site.webmanifest">
    <link rel="shortcut icon" href="/static/favicon.ico">
    
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary: #00ffc8;
            --secondary: #00d4ff;
            --accent: #0088ff;
            --bg-dark: #000a15;
            --bg-card: rgba(0, 30, 50, 0.85);
            --text: #ffffff;
            --text-dim: rgba(255, 255, 255, 0.6);
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-dark);
            color: var(--text);
            min-height: 100vh;
            overflow: hidden;
        }

        /* Matrix Rain Canvas */
        #matrix-canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 0;
        }

        /* Main App Container */
        .app-container {
            position: relative;
            z-index: 1;
            height: 100vh;
            display: flex;
            flex-direction: column;
            max-width: 800px;
            margin: 0 auto;
        }

        /* Header */
        .header {
            text-align: center;
            padding: 20px 15px;
            background: linear-gradient(180deg, rgba(0, 20, 40, 0.95) 0%, transparent 100%);
        }

        .header h1 {
            font-size: clamp(22px, 6vw, 32px);
            font-weight: 700;
            background: linear-gradient(135deg, var(--primary), var(--secondary), var(--accent));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 5px;
        }

        .header .subtitle {
            font-size: 11px;
            color: rgba(0, 255, 200, 0.6);
            letter-spacing: 3px;
            text-transform: uppercase;
        }

        /* Connection Status */
        .connection-status {
            display: inline-flex;
            align-items: center;
            gap: 6px;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 11px;
            margin-top: 10px;
            background: rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            animation: pulse-dot 2s ease-in-out infinite;
        }

        .status-dot.connected { background: #00ff88; box-shadow: 0 0 10px #00ff88; }
        .status-dot.disconnected { background: #ff4444; box-shadow: 0 0 10px #ff4444; }
        .status-dot.connecting { background: #ffaa00; box-shadow: 0 0 10px #ffaa00; }

        @keyframes pulse-dot {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        /* Mode Toggle */
        .mode-toggle {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-top: 15px;
        }

        .mode-btn {
            padding: 10px 24px;
            border-radius: 25px;
            border: 1px solid rgba(0, 255, 200, 0.3);
            background: transparent;
            color: var(--text-dim);
            font-size: 13px;
            font-weight: 600;
            cursor: pointer;
            text-transform: uppercase;
            letter-spacing: 1px;
            transition: all 0.3s ease;
        }

        .mode-btn.active {
            border-color: var(--primary);
            background: rgba(0, 255, 200, 0.15);
            color: var(--primary);
            box-shadow: 0 0 20px rgba(0, 255, 200, 0.2);
        }

        .mode-btn:hover {
            background: rgba(0, 255, 200, 0.1);
        }

        /* TTS Toggle */
        .tts-toggle {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            margin-top: 12px;
        }

        .tts-toggle label {
            font-size: 12px;
            color: var(--text-dim);
        }

        .toggle-switch {
            position: relative;
            width: 50px;
            height: 26px;
            background: rgba(0, 40, 60, 0.8);
            border: 1px solid rgba(0, 255, 200, 0.3);
            border-radius: 13px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .toggle-switch.active {
            background: rgba(0, 255, 200, 0.3);
            border-color: var(--primary);
        }

        .toggle-switch::after {
            content: '';
            position: absolute;
            top: 3px;
            left: 3px;
            width: 18px;
            height: 18px;
            background: var(--text-dim);
            border-radius: 50%;
            transition: all 0.3s ease;
        }

        .toggle-switch.active::after {
            left: 27px;
            background: var(--primary);
            box-shadow: 0 0 10px var(--primary);
        }

        /* Messages Area */
        .messages-container {
            flex: 1;
            overflow-y: auto;
            padding: 20px 15px;
            scroll-behavior: smooth;
        }

        .messages-container::-webkit-scrollbar {
            width: 6px;
        }

        .messages-container::-webkit-scrollbar-track {
            background: rgba(0, 20, 40, 0.5);
        }

        .messages-container::-webkit-scrollbar-thumb {
            background: rgba(0, 255, 200, 0.3);
            border-radius: 3px;
        }

        /* Message Bubbles */
        .message {
            display: flex;
            margin-bottom: 16px;
            animation: slideIn 0.3s ease-out;
        }

        .message.user {
            justify-content: flex-end;
        }

        .message.assistant {
            justify-content: flex-start;
        }

        .message-bubble {
            max-width: 85%;
            padding: 14px 18px;
            border-radius: 20px;
            backdrop-filter: blur(10px);
            word-break: break-word;
        }

        .message.user .message-bubble {
            background: linear-gradient(135deg, rgba(0, 100, 255, 0.85), rgba(0, 150, 255, 0.65));
            border-radius: 20px 20px 4px 20px;
            border: 1px solid rgba(0, 200, 255, 0.3);
            box-shadow: 0 4px 25px rgba(0, 100, 255, 0.25);
        }

        .message.assistant .message-bubble {
            background: linear-gradient(135deg, rgba(0, 40, 60, 0.9), rgba(0, 60, 80, 0.8));
            border-radius: 20px 20px 20px 4px;
            border: 1px solid rgba(0, 255, 200, 0.2);
            box-shadow: 0 4px 25px rgba(0, 0, 0, 0.3);
        }

        .message-text {
            font-size: 15px;
            line-height: 1.5;
        }

        /* Audio Player in Message */
        .message-audio {
            margin-top: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .audio-play-btn {
            width: 36px;
            height: 36px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: white;
            font-size: 14px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }

        .audio-play-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 0 15px rgba(0, 255, 200, 0.5);
        }

        .audio-play-btn.playing {
            background: linear-gradient(135deg, #ff6b6b, #ff4444);
        }

        .audio-wave {
            display: flex;
            align-items: center;
            gap: 2px;
            height: 20px;
        }

        .audio-wave span {
            width: 3px;
            background: var(--primary);
            border-radius: 2px;
            animation: wave 1s ease-in-out infinite;
        }

        .audio-wave span:nth-child(1) { animation-delay: 0s; height: 8px; }
        .audio-wave span:nth-child(2) { animation-delay: 0.1s; height: 16px; }
        .audio-wave span:nth-child(3) { animation-delay: 0.2s; height: 10px; }
        .audio-wave span:nth-child(4) { animation-delay: 0.3s; height: 18px; }
        .audio-wave span:nth-child(5) { animation-delay: 0.4s; height: 12px; }

        @keyframes wave {
            0%, 100% { transform: scaleY(1); }
            50% { transform: scaleY(0.5); }
        }

        .audio-wave.paused span {
            animation: none;
            height: 6px !important;
            opacity: 0.5;
        }

        /* Attachments */
        .attachments-preview {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 10px;
        }

        .attachment-item {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 8px 12px;
            background: rgba(0, 255, 200, 0.1);
            border: 1px solid rgba(0, 255, 200, 0.2);
            border-radius: 10px;
            position: relative;
        }

        .attachment-item img {
            width: 50px;
            height: 50px;
            object-fit: cover;
            border-radius: 6px;
        }

        .attachment-name {
            font-size: 12px;
            color: var(--primary);
            max-width: 80px;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
        }

        .attachment-remove {
            position: absolute;
            top: -8px;
            right: -8px;
            width: 22px;
            height: 22px;
            border-radius: 50%;
            border: none;
            background: #ff4444;
            color: white;
            font-size: 14px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        /* Voice Mode */
        .voice-container {
            padding: 30px 20px;
            text-align: center;
        }

        .orb-container {
            position: relative;
            width: 140px;
            height: 140px;
            margin: 0 auto 20px;
        }

        .orb-ring {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            border-radius: 50%;
            border: 2px solid rgba(0, 255, 200, 0.2);
            animation: pulse 2s ease-in-out infinite;
        }

        .orb-ring:nth-child(1) { width: 100%; height: 100%; animation-delay: 0s; }
        .orb-ring:nth-child(2) { width: 130%; height: 130%; animation-delay: 0.3s; }
        .orb-ring:nth-child(3) { width: 160%; height: 160%; animation-delay: 0.6s; }

        .orb-ring.recording {
            border-color: rgba(255, 80, 80, 0.3);
        }

        .orb-core {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: radial-gradient(circle at 30% 30%, #00ffc8, #00d4ff, #0066ff);
            box-shadow: 
                0 0 40px rgba(0, 255, 200, 0.5),
                0 0 80px rgba(0, 212, 255, 0.3),
                inset 0 0 20px rgba(255, 255, 255, 0.2);
            animation: float 3s ease-in-out infinite;
            transition: all 0.3s ease;
        }

        .orb-core.recording {
            background: radial-gradient(circle at 30% 30%, #ff6b6b, #ff0000, #990000);
            box-shadow: 
                0 0 40px rgba(255, 0, 0, 0.5),
                0 0 80px rgba(255, 0, 0, 0.3),
                inset 0 0 20px rgba(255, 255, 255, 0.2);
        }

        .orb-core.processing {
            background: radial-gradient(circle at 30% 30%, #ffd700, #ff8c00, #ff4500);
            animation: spin 1.5s linear infinite;
        }

        .orb-core.speaking {
            background: radial-gradient(circle at 30% 30%, #a855f7, #7c3aed, #5b21b6);
            box-shadow: 
                0 0 40px rgba(168, 85, 247, 0.5),
                0 0 80px rgba(124, 58, 237, 0.3),
                inset 0 0 20px rgba(255, 255, 255, 0.2);
            animation: pulse-speak 0.5s ease-in-out infinite;
        }

        @keyframes pulse-speak {
            0%, 100% { transform: translate(-50%, -50%) scale(1); }
            50% { transform: translate(-50%, -50%) scale(1.1); }
        }

        .orb-highlight {
            position: absolute;
            top: 15%;
            left: 20%;
            width: 25%;
            height: 25%;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.4);
            filter: blur(4px);
        }

        .orb-status {
            margin-top: 10px;
            font-size: 12px;
            letter-spacing: 2px;
            text-transform: uppercase;
            font-weight: 600;
        }

        .orb-status.ready { color: var(--primary); }
        .orb-status.recording { color: #ff6b6b; }
        .orb-status.processing { color: #ffd700; }
        .orb-status.speaking { color: #a855f7; }

        .record-btn {
            margin-top: 20px;
            padding: 16px 45px;
            border-radius: 30px;
            border: none;
            background: linear-gradient(135deg, var(--primary), var(--accent));
            color: white;
            font-size: 16px;
            font-weight: 700;
            cursor: pointer;
            text-transform: uppercase;
            letter-spacing: 2px;
            box-shadow: 0 0 30px rgba(0, 255, 200, 0.4);
            transition: all 0.3s ease;
        }

        .record-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 0 40px rgba(0, 255, 200, 0.6);
        }

        .record-btn.recording {
            background: linear-gradient(135deg, #ff4444, #cc0000);
            box-shadow: 0 0 30px rgba(255, 0, 0, 0.5);
        }

        .record-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        /* Text Input Area */
        .input-container {
            padding: 15px;
            background: linear-gradient(180deg, transparent 0%, rgba(0, 20, 40, 0.95) 30%);
        }

        .input-row {
            display: flex;
            gap: 10px;
            align-items: flex-end;
        }

        .input-wrapper {
            flex: 1;
            position: relative;
        }

        .text-input {
            width: 100%;
            padding: 14px 18px;
            border-radius: 25px;
            border: 2px solid rgba(0, 255, 200, 0.3);
            background: rgba(0, 20, 40, 0.9);
            color: white;
            font-size: 15px;
            font-family: inherit;
            outline: none;
            resize: none;
            min-height: 50px;
            max-height: 120px;
            transition: all 0.3s ease;
        }

        .text-input:focus {
            border-color: var(--primary);
            box-shadow: 0 0 25px rgba(0, 255, 200, 0.3);
        }

        .text-input::placeholder {
            color: rgba(255, 255, 255, 0.4);
        }

        .icon-btn {
            width: 48px;
            height: 48px;
            border-radius: 50%;
            border: 2px solid rgba(0, 255, 200, 0.3);
            background: rgba(0, 40, 60, 0.8);
            color: var(--primary);
            font-size: 20px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
            flex-shrink: 0;
        }

        .icon-btn:hover {
            background: rgba(0, 255, 200, 0.2);
            box-shadow: 0 0 20px rgba(0, 255, 200, 0.4);
        }

        .send-btn {
            background: linear-gradient(135deg, var(--primary), var(--accent));
            border: none;
            box-shadow: 0 0 20px rgba(0, 255, 200, 0.4);
        }

        .send-btn:disabled {
            background: rgba(100, 100, 100, 0.5);
            box-shadow: none;
            cursor: not-allowed;
        }

        /* Quick Actions */
        .quick-actions {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-top: 12px;
            flex-wrap: wrap;
        }

        .quick-btn {
            padding: 8px 16px;
            border-radius: 16px;
            border: 1px solid rgba(0, 255, 200, 0.2);
            background: transparent;
            color: var(--text-dim);
            font-size: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .quick-btn:hover {
            background: rgba(0, 255, 200, 0.1);
            color: var(--primary);
        }

        /* Footer */
        .footer {
            padding: 12px;
            text-align: center;
            background: rgba(0, 10, 20, 0.9);
        }

        .footer p {
            font-size: 10px;
            color: rgba(0, 255, 200, 0.4);
            letter-spacing: 1px;
        }

        /* Hidden file input */
        .file-input {
            display: none;
        }

        /* Animations */
        @keyframes pulse {
            0%, 100% { transform: translate(-50%, -50%) scale(1); opacity: 0.6; }
            50% { transform: translate(-50%, -50%) scale(1.1); opacity: 0.3; }
        }

        @keyframes float {
            0%, 100% { transform: translate(-50%, -50%) translateY(0); }
            50% { transform: translate(-50%, -50%) translateY(-8px); }
        }

        @keyframes spin {
            0% { transform: translate(-50%, -50%) rotate(0deg); }
            100% { transform: translate(-50%, -50%) rotate(360deg); }
        }

        @keyframes slideIn {
            from { opacity: 0; transform: translateY(15px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Mobile Optimizations */
        @media (max-width: 600px) {
            .header { padding: 15px 10px; }
            .messages-container { padding: 15px 10px; }
            .input-container { padding: 12px 10px; }
            .message-bubble { max-width: 90%; padding: 12px 15px; }
            .icon-btn { width: 44px; height: 44px; }
            .text-input { padding: 12px 15px; }
        }

        /* Typing indicator */
        .typing-indicator {
            display: flex;
            gap: 4px;
            padding: 10px;
        }

        .typing-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: var(--primary);
            animation: typingBounce 1.4s ease-in-out infinite;
        }

        .typing-dot:nth-child(2) { animation-delay: 0.2s; }
        .typing-dot:nth-child(3) { animation-delay: 0.4s; }

        @keyframes typingBounce {
            0%, 60%, 100% { transform: translateY(0); }
            30% { transform: translateY(-8px); }
        }

/* Voice Drop Down section */
.voice-selector {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 5px;
    margin-top: 15px;
}

.voice-selector label {
    font-size: 11px;
    color: var(--text-dim);
    letter-spacing: 1px;
    text-transform: uppercase;
}

#voice-select {
    background: rgba(0, 40, 60, 0.8);
    border: 1px solid rgba(0, 255, 200, 0.3);
    color: var(--primary);
    padding: 8px 12px;
    border-radius: 15px;
    font-family: 'Inter', sans-serif;
    font-size: 12px;
    outline: none;
    cursor: pointer;
    width: 200px;
    text-align: center;
    transition: all 0.3s ease;
}

#voice-select:hover {
    border-color: var(--primary);
    box-shadow: 0 0 15px rgba(0, 255, 200, 0.2);
}

#voice-select option {
    background: #001e32;
    color: white;
}

/* Thinking Window Styles */
.thinking-box {
    margin-bottom: 8px;
    border: 1px dashed rgba(0, 255, 200, 0.3);
    background: rgba(0, 20, 30, 0.5);
    border-radius: 12px;
    overflow: hidden;
    font-size: 13px;
    animation: slideIn 0.3s ease-out;
}

.thinking-header {
    padding: 8px 12px;
    background: rgba(0, 255, 200, 0.05);
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 8px;
    color: var(--primary);
    font-family: 'JetBrains Mono', monospace;
    font-size: 11px;
    text-transform: uppercase;
    letter-spacing: 1px;
    user-select: none;
}

.thinking-header:hover {
    background: rgba(0, 255, 200, 0.1);
}

.thinking-icon {
    animation: pulse 2s infinite;
}

.thinking-content {
    padding: 12px;
    color: rgba(255, 255, 255, 0.7);
    font-family: 'JetBrains Mono', monospace;
    font-size: 12px;
    line-height: 1.5;
    white-space: pre-wrap;
    border-top: 1px solid rgba(0, 255, 200, 0.1);
    display: none; /* Hidden by default */
}

.thinking-box.open .thinking-content {
    display: block;
}

.thinking-box.open .arrow {
    transform: rotate(180deg);
}

.arrow {
    margin-left: auto;
    transition: transform 0.3s ease;
    font-size: 10px;
}

/* ============================================
   Transcribe Section Styles
   ============================================ */
.transcribe-container {
    padding: 20px;
    max-width: 700px;
    margin: 0 auto;
}

.transcribe-upload {
    border: 2px dashed var(--border);
    border-radius: 12px;
    padding: 40px 20px;
    text-align: center;
    cursor: pointer;
    transition: all 0.3s ease;
    background: rgba(0, 255, 200, 0.02);
    margin: 20px 0;
}

.transcribe-upload:hover {
    border-color: var(--primary);
    background: rgba(0, 255, 200, 0.08);
}

.transcribe-upload.dragover {
    border-color: var(--primary);
    background: rgba(0, 255, 200, 0.15);
    transform: scale(1.02);
}

.upload-icon {
    font-size: 48px;
    margin-bottom: 10px;
}

.upload-text {
    font-size: 16px;
    color: var(--text);
    margin-bottom: 8px;
}

.upload-formats {
    font-size: 12px;
    color: var(--text-dim);
}

.transcribe-start-btn {
    width: 100%;
    padding: 15px;
    background: linear-gradient(135deg, var(--primary), #00aa88);
    color: black;
    font-weight: bold;
    font-size: 16px;
    border: none;
    border-radius: 8px;
    cursor: pointer;
    transition: all 0.3s ease;
}

.transcribe-start-btn:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 20px rgba(0, 255, 200, 0.4);
}

.transcribe-start-btn:disabled {
    background: var(--surface);
    color: var(--text-dim);
    cursor: not-allowed;
    transform: none;
    box-shadow: none;
}

.transcribe-spinner {
    width: 50px;
    height: 50px;
    border: 4px solid var(--surface);
    border-top-color: var(--primary);
    border-radius: 50%;
    animation: spin 1s linear infinite;
    margin: 0 auto;
}

@keyframes spin {
    to { transform: rotate(360deg); }
}

.transcribe-action-btn {
    padding: 8px 12px;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: 6px;
    color: var(--text);
    cursor: pointer;
    font-size: 12px;
    transition: all 0.2s ease;
}

.transcribe-action-btn:hover {
    background: var(--primary);
    color: black;
    border-color: var(--primary);
}

.meta-badge {
    background: var(--surface);
    padding: 5px 12px;
    border-radius: 20px;
    font-size: 12px;
    color: var(--text-dim);
    border: 1px solid var(--border);
}

#transcribe-segments .segment-item {
    display: flex;
    gap: 10px;
    padding: 8px;
    border-bottom: 1px solid var(--border);
    font-size: 13px;
}

#transcribe-segments .segment-time {
    color: var(--primary);
    font-family: monospace;
    white-space: nowrap;
}

#transcribe-segments .segment-text {
    color: var(--text);
}

/* Progress Bar Styles */
.progress-container {
    width: 100%;
    background: rgba(255, 255, 255, 0.1);
    border-radius: 10px;
    overflow: hidden;
    margin-top: 15px;
    height: 8px;
    position: relative;
}

.progress-bar {
    height: 100%;
    background: linear-gradient(90deg, var(--primary), var(--accent));
    width: 0%;
    transition: width 0.3s ease;
    box-shadow: 0 0 10px var(--primary);
    position: relative;
    overflow: hidden;
}

/* Shimmer effect for active processing */
.progress-bar::after {
    content: "";
    position: absolute;
    top: 0;
    left: 0;
    bottom: 0;
    right: 0;
    background-image: linear-gradient(
        -45deg,
        rgba(255, 255, 255, 0.2) 25%,
        transparent 25%,
        transparent 50%,
        rgba(255, 255, 255, 0.2) 50%,
        rgba(255, 255, 255, 0.2) 75%,
        transparent 75%,
        transparent
    );
    background-size: 50px 50px;
    animation: move 2s linear infinite;
    z-index: 1;
}

@keyframes move {
    0% { background-position: 0 0; }
    100% { background-position: 50px 50px; }
}
    </style>
    
    <!-- Voice Activity Detection Library -->
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.19/dist/bundle.min.js"></script>
</head>
<body>
    <!-- Matrix Rain Canvas -->
    <canvas id="matrix-canvas"></canvas>

    <!-- Hidden Audio Element -->
    <audio id="audio-player" style="display: none;"></audio>

    <!-- Main App -->
    <div class="app-container">
        <!-- Header -->
        <header class="header">
            <h1>NEMOTRON AI</h1>
            <p class="subtitle">Neural Voice Assistant</p>
            
            <div class="connection-status" id="connection-status">
                <span class="status-dot connecting" id="status-dot"></span>
                <span id="status-text">Connecting...</span>
            </div>
            
            <div class="mode-toggle">
                <button class="mode-btn active" data-mode="text" onclick="setMode('text')">‚å®Ô∏è Text</button>
                <button class="mode-btn" data-mode="voice" onclick="setMode('voice')">üé§ Voice</button>
                <button class="mode-btn" data-mode="transcribe" onclick="setMode('transcribe')">üéß Transcribe</button>
            </div>

            <div class="tts-toggle">
                <label>üîä Text-to-Speech</label>
                <div class="toggle-switch active" id="tts-toggle" onclick="toggleTTS()"></div>
            </div>

            <div class="tts-toggle">
                <label>üß† Deep Think</label>
                <div class="toggle-switch" id="think-toggle" onclick="toggleThinking()"></div>
            </div>

<div class="voice-selector">
    <label>üó£Ô∏è Voice Identity</label>
    <select id="voice-select" onchange="updateVoicePreference()">
        <optgroup label="Standard Voices">
            <option value="en_0" selected>Speaker 0 (Male Default)</option>
            <option value="en_1">Speaker 1 (Male Deep)</option>
            <option value="en_10">Speaker 10 (Female Soft)</option>
            <option value="en_21">Speaker 21 (Male British)</option>
            <option value="en_42">Speaker 42 (Female Clear)</option>
        </optgroup>
        <optgroup label="All Neural Voices">
            </optgroup>
    </select>
</div>

        </header>

        <!-- Messages -->
        <div class="messages-container" id="messages-container">
            <div class="message assistant">
                <div class="message-bubble">
                    <p class="message-text">Hello! I'm your Nemotron AI assistant powered by NVIDIA's neural speech models. How can I help you today?</p>
                </div>
            </div>
        </div>

        <!-- Voice Mode -->
        <div class="voice-container" id="voice-container" style="display: none;">
            <div class="orb-container">
                <div class="orb-ring" id="ring1"></div>
                <div class="orb-ring" id="ring2"></div>
                <div class="orb-ring" id="ring3"></div>
                <div class="orb-core" id="orb-core">
                    <div class="orb-highlight"></div>
                </div>
            </div>
            <div class="orb-status ready" id="orb-status">‚óâ READY</div>
            
            <!-- Voice Mode Toggle -->
            <div class="voice-mode-toggle" style="margin: 10px 0; display: flex; gap: 10px; justify-content: center;">
                <button class="quick-btn" id="push-to-talk-btn" onclick="setVoiceMode('push')" style="background: var(--primary); color: black;">Push to Talk</button>
                <button class="quick-btn" id="continuous-btn" onclick="setVoiceMode('continuous')">üéôÔ∏è Conversation</button>
            </div>
            
            <button class="record-btn" id="record-btn" onclick="toggleRecording()">‚óè Record</button>
            
            <!-- Live transcript display -->
            <div id="live-transcript" style="margin-top: 15px; padding: 10px; background: rgba(0,255,200,0.1); border-radius: 8px; min-height: 30px; font-style: italic; color: var(--primary); display: none;"></div>
        </div>

        <!-- Transcribe Container -->
        <div class="transcribe-container" id="transcribe-container" style="display: none;">
            <div class="transcribe-header">
                <h3 style="color: var(--primary); margin: 0 0 10px 0;">üéß File Transcription</h3>
                <p style="color: var(--text-dim); font-size: 12px; margin: 0;">Powered by Whisper ‚Ä¢ Supports MP3, MP4, M4A, WAV, FLAC, MKV, AVI</p>
            </div>
            
            <!-- Upload Area -->
            <div class="transcribe-upload" id="transcribe-upload-area" onclick="document.getElementById('transcribe-file-input').click()">
                <input type="file" id="transcribe-file-input" accept=".mp3,.mp4,.m4a,.wav,.flac,.ogg,.webm,.avi,.mkv,.mov,.aac,.wma" onchange="handleTranscribeFile(event)" style="display: none;">
                <div class="upload-icon">üìÅ</div>
                <div class="upload-text">Click or drag file to upload</div>
                <div class="upload-formats">MP3 ‚Ä¢ MP4 ‚Ä¢ M4A ‚Ä¢ WAV ‚Ä¢ FLAC ‚Ä¢ MKV ‚Ä¢ AVI ‚Ä¢ MOV</div>
            </div>
            
            <!-- File Info -->
            <div id="transcribe-file-info" style="display: none;">
                <div style="display: flex; align-items: center; gap: 10px; padding: 15px; background: rgba(0,255,200,0.1); border-radius: 8px; margin: 15px 0;">
                    <span style="font-size: 24px;">üéµ</span>
                    <div style="flex: 1;">
                        <div id="transcribe-filename" style="font-weight: bold; color: var(--text);"></div>
                        <div id="transcribe-filesize" style="font-size: 12px; color: var(--text-dim);"></div>
                    </div>
                    <button onclick="clearTranscribeFile()" style="background: #ff4444; color: white; border: none; border-radius: 4px; padding: 5px 10px; cursor: pointer;">‚úï Remove</button>
                </div>
                
                <!-- Language Selection -->
                <div style="margin: 15px 0;">
                    <label style="color: var(--text-dim); font-size: 12px;">Language (optional - auto-detects if empty)</label>
                    <select id="transcribe-language" style="width: 100%; padding: 10px; background: var(--surface); border: 1px solid var(--border); border-radius: 8px; color: var(--text); margin-top: 5px;">
                        <option value="">Auto-detect</option>
                        <option value="en">English</option>
                        <option value="es">Spanish</option>
                        <option value="fr">French</option>
                        <option value="de">German</option>
                        <option value="it">Italian</option>
                        <option value="pt">Portuguese</option>
                        <option value="ru">Russian</option>
                        <option value="ja">Japanese</option>
                        <option value="ko">Korean</option>
                        <option value="zh">Chinese</option>
                    </select>
                </div>
                
                <button id="transcribe-btn" onclick="startTranscription()" class="transcribe-start-btn">
                    üöÄ Start Transcription
                </button>
            </div>
            
            <!-- Progress -->
            <div id="transcribe-progress" style="display: none;">
                <div style="text-align: center; padding: 30px;">
                    <div class="transcribe-spinner"></div>
                    <div style="color: var(--primary); margin-top: 15px; font-weight: bold;">Transcribing Now...</div>
                    
                    <div class="progress-container">
                        <div class="progress-bar" id="real-progress-bar"></div>
                    </div>
                    
                    <div id="transcribe-progress-text" style="color: var(--text-dim); font-size: 12px; margin-top: 5px;">Processing audio data...</div>
                </div>
            </div>

            <!-- Results -->
            <div id="transcribe-results" style="display: none;">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                    <h4 style="color: var(--primary); margin: 0;">üìù Transcription Result</h4>
                    <div style="display: flex; gap: 10px;">
                        <button onclick="copyTranscript()" class="transcribe-action-btn">üìã Copy</button>
                        <button onclick="downloadTranscript()" class="transcribe-action-btn">üíæ Download</button>
                        <button onclick="newTranscription()" class="transcribe-action-btn">üîÑ New</button>
                    </div>
                </div>
                
                <!-- Meta Info -->
                <div id="transcribe-meta" style="display: flex; gap: 15px; margin-bottom: 15px; flex-wrap: wrap;">
                    <span class="meta-badge" id="meta-language">üåê English</span>
                    <span class="meta-badge" id="meta-duration">‚è±Ô∏è 0:00</span>
                    <span class="meta-badge" id="meta-time">‚ö° 0.0s</span>
                </div>
                
                <!-- Transcript Text -->
                <div id="transcribe-text" style="background: var(--surface); border: 1px solid var(--border); border-radius: 8px; padding: 15px; max-height: 300px; overflow-y: auto; white-space: pre-wrap; line-height: 1.6;"></div>
                
                <!-- Segments Toggle -->
                <details style="margin-top: 15px;">
                    <summary style="cursor: pointer; color: var(--primary); font-weight: bold;">üìä Show Timestamps</summary>
                    <div id="transcribe-segments" style="margin-top: 10px; max-height: 200px; overflow-y: auto;"></div>
                </details>
            </div>
        </div>

        <!-- Text Input -->
        <div class="input-container" id="input-container">
            <!-- Attachments Preview -->
            <div class="attachments-preview" id="attachments-preview"></div>
            
            <!-- Image Preview (for vision) -->
            <div id="image-preview-container" style="display: none; margin-bottom: 10px;">
                <div style="position: relative; display: inline-block;">
                    <img id="image-preview" style="max-width: 200px; max-height: 150px; border-radius: 8px; border: 2px solid var(--primary);">
                    <button onclick="clearImagePreview()" style="position: absolute; top: -8px; right: -8px; background: #ff4444; color: white; border: none; border-radius: 50%; width: 24px; height: 24px; cursor: pointer; font-size: 14px;">√ó</button>
                </div>
                <p style="font-size: 11px; color: var(--text-dim); margin-top: 5px;">üëÅÔ∏è Image will be analyzed</p>
            </div>

            <div class="input-row">
                <input type="file" class="file-input" id="file-input" multiple accept="image/*,.pdf,.doc,.docx,.txt,.json,.csv" onchange="handleFiles(event)">
                <button class="icon-btn" onclick="document.getElementById('file-input').click()">üìé</button>
                
                <div class="input-wrapper">
                    <textarea 
                        class="text-input" 
                        id="text-input" 
                        placeholder="Type your message..." 
                        rows="1"
                        onkeypress="handleKeyPress(event)"
                        oninput="autoResize(this)"
                    ></textarea>
                </div>
                
                <button class="icon-btn send-btn" id="send-btn" onclick="sendMessage()">‚û§</button>
            </div>

            <div class="quick-actions">
                <button class="quick-btn" onclick="setMode('voice')">üé§ Voice</button>
                <button class="quick-btn" onclick="setMode('transcribe')">üéß Transcribe</button>
                <button class="quick-btn" onclick="document.getElementById('file-input').click()">üì∑ Upload</button>
                <button class="quick-btn" onclick="manualWebSearch()">üåê Search Web</button>
                <button class="quick-btn" onclick="clearChat()">üóëÔ∏è Clear</button>
            </div>
        </div>

        <!-- Footer -->
        <footer class="footer">
            <p>POWERED BY NVIDIA NEMOTRON ‚Ä¢ ASR + LLM + TTS + VISION + WHISPER + VAD</p>
        </footer>
    </div>

    <script>
        // ============================================
        // Configuration - UPDATE THIS TO YOUR SERVER
        // ============================================
        const API_BASE = window.location.origin; // Uses same origin as page
        // If running separately, use: const API_BASE = 'http://localhost:5050';

        // ============================================
        // Matrix Rain Animation
        // ============================================
        const canvas = document.getElementById('matrix-canvas');
        const ctx = canvas.getContext('2d');

        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        }
        resizeCanvas();
        window.addEventListener('resize', resizeCanvas);

        const chars = '„Ç¢„Ç§„Ç¶„Ç®„Ç™„Ç´„Ç≠„ÇØ„Ç±„Ç≥„Çµ„Ç∑„Çπ„Çª„ÇΩ„Çø„ÉÅ„ÉÑ„ÉÜ„Éà„Éä„Éã„Éå„Éç„Éé„Éè„Éí„Éï„Éò„Éõ„Éû„Éü„É†„É°„É¢„É§„É¶„É®„É©„É™„É´„É¨„É≠„ÉØ„É≤„É≥0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ<>{}[]|/\\';
        const charArray = chars.split('');
        const fontSize = 14;
        let columns = canvas.width / fontSize;
        let drops = [];

        function initDrops() {
            columns = canvas.width / fontSize;
            drops = [];
            for (let i = 0; i < columns; i++) {
                drops[i] = Math.random() * -100;
            }
        }
        initDrops();
        window.addEventListener('resize', initDrops);

        function drawMatrix() {
            ctx.fillStyle = 'rgba(0, 5, 15, 0.05)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            for (let i = 0; i < drops.length; i++) {
                const char = charArray[Math.floor(Math.random() * charArray.length)];
                const x = i * fontSize;
                const y = drops[i] * fontSize;

                const rand = Math.random();
                if (rand > 0.98) {
                    ctx.fillStyle = '#ffffff';
                } else if (rand > 0.7) {
                    ctx.fillStyle = '#00ffc8';
                } else if (rand > 0.4) {
                    ctx.fillStyle = '#00d4ff';
                } else {
                    ctx.fillStyle = 'rgba(0, 180, 200, 0.7)';
                }

                ctx.font = `${fontSize}px 'JetBrains Mono', monospace`;
                ctx.fillText(char, x, y);

                if (y > canvas.height && Math.random() > 0.975) {
                    drops[i] = 0;
                }
                drops[i]++;
            }
        }

        setInterval(drawMatrix, 35);

        // ============================================
        // State
        // ============================================
        let currentMode = 'text';
        let isRecording = false;
        let isProcessing = false;
        let isSpeaking = false;
        let ttsEnabled = true;
        let attachments = [];
        let mediaRecorder = null;
        let audioChunks = [];
        let currentAudio = null;
        let isConnected = false;
        let isThinkingEnabled = false;
        let deepThinkEnabled = false;
        
        // Voice mode: 'push' (push-to-talk) or 'continuous' (VAD-based auto-detect)
        let voiceMode = 'push';
        // VAD instance is managed in the VAD section below
        
        // Image handling
        let currentImageData = null; // Base64 image data for vision

        // ============================================
        // Connection Check
        // ============================================
        async function checkConnection() {
            const dot = document.getElementById('status-dot');
            const text = document.getElementById('status-text');
            
            try {
                const response = await fetch(`${API_BASE}/health`, { 
                    method: 'GET',
                    timeout: 5000 
                });
                
                if (response.ok) {
                    const data = await response.json();
                    dot.className = 'status-dot connected';
                    
                    // Build status text with features
                    let statusParts = ['Connected'];
                    if (data.thinking_mode) statusParts.push('üß† Think');
                    if (data.weather_configured) statusParts.push('üå§Ô∏è Weather');
                    text.textContent = statusParts.join(' ‚Ä¢ ');
                    
                    isConnected = true;

                    isThinkingEnabled = data.thinking_mode === true;
                    if(isThinkingEnabled) {
                        console.log("üß† Reasoning Mode Detected");
                    }

                    if (data.thinking_mode === true && !deepThinkEnabled) {
                        toggleThinking(); // Turn it on if server started with --think
                    }
                } else {
                    throw new Error('Server error');
                }
            } catch (err) {
                dot.className = 'status-dot disconnected';
                text.textContent = 'Disconnected - Using Demo Mode';
                isConnected = false;
            }
        }

        // Check connection on load and periodically
        checkConnection();
        setInterval(checkConnection, 30000);

        // ============================================
        // TTS Toggle
        // ============================================
        function toggleTTS() {
            ttsEnabled = !ttsEnabled;
            const toggle = document.getElementById('tts-toggle');
            toggle.classList.toggle('active', ttsEnabled);
        }

        // ============================================
        //  Deep Think Toggle
        // ============================================
        function toggleThinking() {
            deepThinkEnabled = !deepThinkEnabled;
            const toggle = document.getElementById('think-toggle');
            toggle.classList.toggle('active', deepThinkEnabled);
            
            // Visual feedback
            const status = deepThinkEnabled ? "üß† Deep Think ON" : "‚ö° Fast Chat ON";
            console.log(status);
        }

        // ============================================
        // Audio Playback
        // ============================================
        function playAudioBase64(base64Audio, messageId) {
            return new Promise((resolve, reject) => {
                try {
                    // Stop any currently playing audio
                    stopCurrentAudio();
                    
                    const audio = document.getElementById('audio-player');
                    audio.src = `data:audio/wav;base64,${base64Audio}`;
                    
                    currentAudio = audio;
                    isSpeaking = true;
                    updateVoiceUI();
                    
                    // Update play button if exists
                    const playBtn = document.getElementById(`play-${messageId}`);
                    if (playBtn) {
                        playBtn.classList.add('playing');
                        playBtn.textContent = '‚èπ';
                    }
                    
                    const waveEl = document.getElementById(`wave-${messageId}`);
                    if (waveEl) waveEl.classList.remove('paused');
                    
                    audio.onended = () => {
                        isSpeaking = false;
                        currentAudio = null;
                        updateVoiceUI();
                        
                        if (playBtn) {
                            playBtn.classList.remove('playing');
                            playBtn.textContent = '‚ñ∂';
                        }
                        if (waveEl) waveEl.classList.add('paused');
                        
                        resolve();
                    };
                    
                    audio.onerror = (e) => {
                        isSpeaking = false;
                        currentAudio = null;
                        updateVoiceUI();
                        reject(e);
                    };
                    
                    audio.play();
                } catch (err) {
                    reject(err);
                }
            });
        }

        function stopCurrentAudio() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio.currentTime = 0;
                isSpeaking = false;
                currentAudio = null;
                updateVoiceUI();
            }
        }

        function togglePlayAudio(messageId, base64Audio) {
            const playBtn = document.getElementById(`play-${messageId}`);
            
            if (currentAudio && !currentAudio.paused) {
                stopCurrentAudio();
                if (playBtn) {
                    playBtn.classList.remove('playing');
                    playBtn.textContent = '‚ñ∂';
                }
            } else {
                playAudioBase64(base64Audio, messageId);
            }
        }

        // ============================================
        // Mode Toggle
        // ============================================
        function setMode(mode) {
            currentMode = mode;
            
            document.querySelectorAll('.mode-btn').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.mode === mode);
            });

            document.getElementById('voice-container').style.display = mode === 'voice' ? 'block' : 'none';
            document.getElementById('input-container').style.display = mode === 'text' ? 'block' : 'none';
            document.getElementById('transcribe-container').style.display = mode === 'transcribe' ? 'block' : 'none';
        }

        // ============================================
        // Message Handling
        // ============================================
        function addMessage(text, isUser, audioBase64 = null, attachmentsList = [], thought = null) {
            const container = document.getElementById('messages-container');
            const messageDiv = document.createElement('div');
            const messageId = Date.now();
            messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;

            let attachmentsHtml = '';
            if (attachmentsList.length > 0) {
                attachmentsHtml = '<div class="attachments-preview" style="margin-bottom: 8px;">';
                attachmentsList.forEach(att => {
                    if (att.type === 'image') {
                        attachmentsHtml += `<div class="attachment-item"><img src="${att.preview}" alt=""></div>`;
                    } else {
                        attachmentsHtml += `<div class="attachment-item">üìé <span class="attachment-name">${att.name}</span></div>`;
                    }
                });
                attachmentsHtml += '</div>';
            }

            let audioHtml = '';
            if (audioBase64 && !isUser) {
                audioHtml = `
                    <div class="message-audio">
                        <button class="audio-play-btn" id="play-${messageId}" onclick="togglePlayAudio('${messageId}', '${audioBase64}')">‚ñ∂</button>
                        <div class="audio-wave paused" id="wave-${messageId}">
                            <span></span><span></span><span></span><span></span><span></span>
                        </div>
                        <span style="font-size: 11px; color: var(--text-dim);">Play Audio</span>
                    </div>
                `;
            }

            messageDiv.innerHTML = `
                <div class="message-bubble">
                    ${attachmentsHtml}
                    <p class="message-text">${text}</p>
                    ${audioHtml}
                </div>
            `;

            let thoughtHtml = '';
            if (thought && !isUser) {
                thoughtHtml = `
                    <div class="thinking-box" onclick="this.classList.toggle('open')">
                        <div class="thinking-header">
                            <span class="thinking-icon">üß†</span> Neural Process
                            <span class="arrow">‚ñº</span>
                        </div>
                        <div class="thinking-content">${thought}</div>
                    </div>
                `;
            }

            messageDiv.innerHTML = `
                <div class="message-bubble">
                    ${thoughtHtml}
                    ${attachmentsHtml}
                    <p class="message-text">${text}</p>
                    ${audioHtml}
                </div>
            `;

            // Store audio data for replay
            if (audioBase64) {
                messageDiv.dataset.audio = audioBase64;
            }

            container.appendChild(messageDiv);
            container.scrollTop = container.scrollHeight;
            
            return messageId;
        }

        function addTypingIndicator() {
            const container = document.getElementById('messages-container');
            const indicator = document.createElement('div');
            indicator.id = 'typing-indicator';
            indicator.className = 'message assistant';
            indicator.innerHTML = `
                <div class="message-bubble">
                    <div class="typing-indicator">
                        <div class="typing-dot"></div>
                        <div class="typing-dot"></div>
                        <div class="typing-dot"></div>
                    </div>
                </div>
            `;
            container.appendChild(indicator);
            container.scrollTop = container.scrollHeight;
        }

        function removeTypingIndicator() {
            const indicator = document.getElementById('typing-indicator');
            if (indicator) indicator.remove();
        }

        // ============================================
        // Send Message
        // ============================================
        async function sendMessage() {
            const input = document.getElementById('text-input');
            const text = input.value.trim();

            if (!text && attachments.length === 0) return;

            const currentAttachments = [...attachments];
            addMessage(text || `Sent ${attachments.length} file(s)`, true, null, currentAttachments);
            
            input.value = '';
            input.style.height = 'auto';
            clearAttachments();

            await getResponse(text, currentAttachments);
        }

        async function getResponse(userMessage, files = [], forceSearch = false) {
            isProcessing = true;
            updateSendButton();
            addTypingIndicator();

            try {
                if (isConnected) {
                    // Use AbortController with longer timeout (120 seconds for AI generation)
                    const controller = new AbortController();
                    //const timeoutId = setTimeout(() => controller.abort(), 120000); // 2 minutes
                    const timeoutId = setTimeout(() => controller.abort(), 300000); // 5 minutes
                    // Use the real backend with TTS
                    const endpoint = ttsEnabled ? '/chat/speak' : '/chat';
                    
                    // Build request body with image if available
                    const requestBody = { 
                        message: userMessage, 
                        files: files.map(f => f.name),
			            voice: selectedVoice,
                        web_search: forceSearch,
                        use_thinking: deepThinkEnabled
                    };
                    
                    // Add image data if available
                    if (currentImageData) {
                        requestBody.image_data = currentImageData;
                        console.log('üì∑ Including image for vision analysis');
                    }
                    
                    const response = await fetch(`${API_BASE}${endpoint}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(requestBody),
                        signal: controller.signal
                    });
                    
                    clearTimeout(timeoutId);
                    
                    // Clear image after sending
                    if (currentImageData) {
                        clearImagePreview();
                    }

                    removeTypingIndicator();
                    
                    if (response.ok) {
                        const data = await response.json();

                        // Server now returns clean spoken_response as data.response
                        // and full thinking content as data.thinking
                        let displayResponse = data.response;
                        let thoughtContent = data.thinking || null;

                        // Light cleanup - just ensure tags are removed (safety)
                        displayResponse = displayResponse.replace(/<think>[\s\S]*?<\/think>/gi, '').trim();
                        displayResponse = displayResponse.replace(/<thinking>[\s\S]*?<\/thinking>/gi, '').trim();
                        
                        // Capitalize first letter if needed
                        if (displayResponse && displayResponse.length > 0) {
                            displayResponse = displayResponse.charAt(0).toUpperCase() + displayResponse.slice(1);
                        }

                        // Fallback if empty
                        if (!displayResponse || displayResponse.length < 5) {
                            displayResponse = "I've processed your request.";
                        }

                        console.log("üß† Thinking:", thoughtContent ? `${thoughtContent.length} chars` : "None");
                        console.log("üó£Ô∏è Display:", displayResponse.substring(0, 100) + "...");

                        // Pass the separated thought to addMessage
                        const messageId = addMessage(displayResponse, false, data.audio_base64, [], thoughtContent);
                        
                        // Auto-play TTS if enabled and audio is available
                        if (ttsEnabled && data.audio_base64) {
                            await playAudioBase64(data.audio_base64, messageId);
                        }
                    } else {
                        throw new Error('Backend error');
                    }
                } else {
                    // Fallback to demo mode
                    await simulatedResponse(userMessage);
                }
            } catch (err) {
                console.error('Error:', err);
                removeTypingIndicator();
                
                // Show specific error message based on error type
                if (err.name === 'AbortError') {
                    addMessage("‚è±Ô∏è Request timed out. The AI is thinking too deeply! Try turning off 'Deep Think' for faster answers.", false);
                } else if (err.message === 'Backend error') {
                    addMessage("‚ö†Ô∏è Network Timeout: The AI is working, but the connection closed. \n\nTip: Try asking a simpler question or disable 'Deep Think' to speed it up.", false);
                } else {
                    await simulatedResponse(userMessage);
                }
            }

            isProcessing = false;
            updateSendButton();
        }

        async function simulatedResponse(userMessage) {
            // Demo mode - simulated responses
            const responses = [
                "I'm currently in demo mode. Start the backend server with 'python nemotron_web_server.py' to enable full AI responses with speech synthesis.",
                "Connect me to the Nemotron backend for real AI-powered conversations! The matrix awaits...",
                "Demo mode active. The neural pathways are simulated. Launch the server for true Nemotron intelligence.",
                "Running in standalone mode. For full ASR + LLM + TTS, ensure the Python backend is running."
            ];
            
            await new Promise(r => setTimeout(r, 800 + Math.random() * 700));
            removeTypingIndicator();
            
            const randomResponse = responses[Math.floor(Math.random() * responses.length)];
            addMessage(randomResponse, false);
        }

        // ============================================
        // File Handling
        // ============================================
        function handleFiles(event) {
            const files = Array.from(event.target.files);
            
            files.forEach(file => {
                const attachment = {
                    file: file,
                    name: file.name,
                    type: file.type.startsWith('image/') ? 'image' : 'file',
                    preview: null
                };

                if (attachment.type === 'image') {
                    attachment.preview = URL.createObjectURL(file);
                }

                attachments.push(attachment);
            });

            renderAttachments();
            event.target.value = '';
        }

        function renderAttachments() {
            const container = document.getElementById('attachments-preview');
            container.innerHTML = '';

            attachments.forEach((att, index) => {
                const item = document.createElement('div');
                item.className = 'attachment-item';
                
                if (att.type === 'image') {
                    item.innerHTML = `
                        <img src="${att.preview}" alt="">
                        <button class="attachment-remove" onclick="removeAttachment(${index})">√ó</button>
                    `;
                } else {
                    item.innerHTML = `
                        üìé <span class="attachment-name">${att.name}</span>
                        <button class="attachment-remove" onclick="removeAttachment(${index})">√ó</button>
                    `;
                }

                container.appendChild(item);
            });
        }

        function removeAttachment(index) {
            if (attachments[index].preview) {
                URL.revokeObjectURL(attachments[index].preview);
            }
            attachments.splice(index, 1);
            renderAttachments();
        }

        function clearAttachments() {
            attachments.forEach(att => {
                if (att.preview) URL.revokeObjectURL(att.preview);
            });
            attachments = [];
            renderAttachments();
        }

        // ============================================
        // Voice Recording
        // ============================================
        async function toggleRecording() {
            if (isProcessing || isSpeaking) return;

            if (isRecording) {
                stopRecording();
            } else {
                await startRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
                
                mediaRecorder.onstop = async () => {
                    stream.getTracks().forEach(track => track.stop());
                    await processRecording();
                };

                mediaRecorder.start();
                isRecording = true;
                updateVoiceUI();
            } catch (err) {
                alert('Please allow microphone access to use voice input.');
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            isRecording = false;
            updateVoiceUI();
        }

        async function processRecording() {
            isProcessing = true;
            updateVoiceUI();

            try {
                if (isConnected) {
                    // Create audio blob and send to backend
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    const formData = new FormData();
                    formData.append('file', audioBlob, 'recording.wav');

                    // First transcribe
                    const transcribeResponse = await fetch(`${API_BASE}/transcribe`, {
                        method: 'POST',
                        body: formData
                    });

                    if (transcribeResponse.ok) {
                        const transcribeData = await transcribeResponse.json();
                        
                        // --- BUG FIX START ---
                        // Force the transcript to be a string, even if server returns an array/object
                        let rawTranscript = transcribeData.transcript;
                        
                        // Handle Array (e.g. ["Hello"])
                        if (Array.isArray(rawTranscript)) {
                            rawTranscript = rawTranscript[0] || "";
                        }
                        
                        // Handle Numbers/Objects by forcing string conversion
                        const transcript = String(rawTranscript || ""); 
                        // --- BUG FIX END ---

                        // Only proceed if we actually have text
                        if (transcript && transcript.trim().length > 0) {
                            addMessage(`üé§ "${transcript}"`, true);
                            // Then get response
                            await getResponse(transcript);
                        } else {
                            console.warn("Empty or invalid transcript received");
                        }

                    } else {
                        throw new Error('Transcription failed');
                    }
                } else {
                    // Demo mode
                    await new Promise(r => setTimeout(r, 1000));
                    const simulatedTranscript = "Voice recording captured (demo mode)";
                    addMessage(`üé§ "${simulatedTranscript}"`, true);
                    await simulatedResponse(simulatedTranscript);
                }
            } catch (err) {
                console.error('Voice processing error:', err);
                addMessage("üé§ Voice processing error. Please try again.", true);
            }

            isProcessing = false;
            updateVoiceUI();
        }

        function updateVoiceUI() {
            const orb = document.getElementById('orb-core');
            const status = document.getElementById('orb-status');
            const btn = document.getElementById('record-btn');
            const rings = document.querySelectorAll('.orb-ring');

            orb.className = 'orb-core';
            rings.forEach(r => r.className = 'orb-ring');

            if (isRecording) {
                orb.classList.add('recording');
                rings.forEach(r => r.classList.add('recording'));
                status.className = 'orb-status recording';
                status.textContent = '‚óè REC';
                btn.className = 'record-btn recording';
                btn.textContent = '‚èπ Stop';
                btn.disabled = false;
            } else if (isProcessing) {
                orb.classList.add('processing');
                status.className = 'orb-status processing';
                status.textContent = '‚óå PROCESSING';
                btn.disabled = true;
                btn.textContent = '‚óå Processing...';
            } else if (isSpeaking) {
                orb.classList.add('speaking');
                status.className = 'orb-status speaking';
                status.textContent = 'üîä SPEAKING';
                btn.disabled = true;
                btn.textContent = 'üîä Speaking...';
            } else {
                status.className = 'orb-status ready';
                status.textContent = '‚óâ READY';
                btn.className = 'record-btn';
                btn.disabled = false;
                btn.textContent = voiceMode === 'continuous' ? 'üéôÔ∏è Start Listening' : '‚óè Record';
            }
        }

        // ============================================
        // Voice Mode Selection
        // ============================================
        function setVoiceMode(mode) {
            voiceMode = mode;
            
            // Update button styles
            document.getElementById('push-to-talk-btn').style.background = mode === 'push' ? 'var(--primary)' : 'transparent';
            document.getElementById('push-to-talk-btn').style.color = mode === 'push' ? 'black' : 'var(--text)';
            document.getElementById('continuous-btn').style.background = mode === 'continuous' ? 'var(--primary)' : 'transparent';
            document.getElementById('continuous-btn').style.color = mode === 'continuous' ? 'black' : 'var(--text)';
            
            // Update record button text
            const btn = document.getElementById('record-btn');
            btn.textContent = mode === 'continuous' ? 'üéôÔ∏è Start Listening' : '‚óè Record';
            
            // Show/hide live transcript
            document.getElementById('live-transcript').style.display = mode === 'continuous' ? 'block' : 'none';
            
            // Stop any current recording
            if (isRecording) {
                stopRecording();
            }
            
            console.log(`Voice mode set to: ${mode}`);
        }

        // ============================================
        // ============================================
        // VAD (Voice Activity Detection) - "Jarvis Mode"
        // Runs 100% locally in browser, no cloud needed!
        // Automatically detects speech start/end
        // ============================================
        // ============================================
        let vadInstance = null;
        let vadAudioContext = null;
        
        async function startContinuousListening() {
            // If VAD already exists, just resume it
            if (vadInstance) {
                vadInstance.start();
                isRecording = true;
                updateVoiceUI();
                document.getElementById('live-transcript').style.display = 'block';
                document.getElementById('live-transcript').textContent = 'üé§ Listening... (speak naturally)';
                return;
            }
            
            try {
                document.getElementById('live-transcript').style.display = 'block';
                document.getElementById('live-transcript').textContent = '‚è≥ Initializing voice detection...';
                
                // Create VAD instance with local processing
                vadInstance = await vad.MicVAD.new({
                    positiveSpeechThreshold: 0.8,  // Confidence threshold
                    negativeSpeechThreshold: 0.5,
                    minSpeechFrames: 5,            // Min frames to count as speech
                    redemptionFrames: 8,           // Frames of silence before speech end
                    
                    onSpeechStart: () => {
                        console.log("üó£Ô∏è Speech started");
                        document.getElementById('live-transcript').textContent = 'üó£Ô∏è Listening...';
                        document.getElementById('orb-core').classList.add('recording');
                        document.getElementById('orb-status').textContent = '‚óè LISTENING';
                        document.getElementById('orb-status').className = 'orb-status recording';
                    },
                    
                    onSpeechEnd: async (audio) => {
                        console.log("ü§´ Speech ended, processing...");
                        document.getElementById('orb-core').classList.remove('recording');
                        document.getElementById('live-transcript').textContent = '‚ö° Processing...';
                        document.getElementById('orb-status').textContent = '‚óê PROCESSING';
                        document.getElementById('orb-status').className = 'orb-status processing';
                        
                        // Process the captured audio
                        await processVadAudio(audio);
                    },
                    
                    onVADMisfire: () => {
                        console.log("‚ö†Ô∏è Background noise ignored");
                        document.getElementById('orb-core').classList.remove('recording');
                    }
                });
                
                // Start listening
                vadInstance.start();
                isRecording = true;
                updateVoiceUI();
                
                document.getElementById('live-transcript').textContent = 'üé§ Listening... (speak naturally)';
                document.getElementById('orb-status').textContent = '‚óâ READY';
                document.getElementById('orb-status').className = 'orb-status ready';
                
                addMessage("üéôÔ∏è **Conversation Mode Active**\n\nJust speak naturally - I'll detect when you're done and respond automatically!", false);
                
            } catch (e) {
                console.error("VAD initialization error:", e);
                document.getElementById('live-transcript').textContent = '‚ùå Voice detection failed';
                
                // Fallback message
                alert(`Voice Activity Detection failed to initialize.\n\nError: ${e.message}\n\nTry using Push-to-Talk mode instead, or check microphone permissions.`);
                
                // Reset state
                isRecording = false;
                updateVoiceUI();
            }
        }
        
        function stopContinuousListening() {
            if (vadInstance) {
                vadInstance.pause();
            }
            isRecording = false;
            document.getElementById('live-transcript').style.display = 'none';
            document.getElementById('live-transcript').textContent = '';
            document.getElementById('orb-status').textContent = '‚óâ READY';
            document.getElementById('orb-status').className = 'orb-status ready';
            document.getElementById('orb-core').classList.remove('recording');
            updateVoiceUI();
        }
        
        async function processVadAudio(audioFloat32) {
            if (isProcessing) return;
            isProcessing = true;
            
            try {
                // Convert Float32Array to WAV blob
                const wavBuffer = encodeWAV(audioFloat32);
                const audioBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                
                console.log(`üì§ Sending ${(audioBlob.size / 1024).toFixed(1)}KB audio to Nemotron ASR`);
                
                // Send to server for transcription
                const formData = new FormData();
                formData.append('file', audioBlob, 'vad_audio.wav');
                
                const response = await fetch(`${API_BASE}/transcribe`, {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    throw new Error(`Transcription failed: ${response.status}`);
                }
                
                const data = await response.json();
                let transcript = data.transcript;
                
                // Handle array response
                if (Array.isArray(transcript)) {
                    transcript = transcript[0];
                }
                
                // Clean up transcript
                transcript = (transcript || '').trim();
                
                if (transcript.length > 0) {
                    console.log(`üìù Transcript: "${transcript}"`);
                    
                    // Show user message
                    addMessage(`üé§ "${transcript}"`, true);
                    
                    // Update status
                    document.getElementById('live-transcript').textContent = 'ü§ñ Thinking...';
                    document.getElementById('orb-status').textContent = '‚óê THINKING';
                    
                    // Get AI response
                    await getResponse(transcript);
                    
                    // Resume listening after response completes
                    if (voiceMode === 'continuous' && isRecording) {
                        document.getElementById('live-transcript').textContent = 'üé§ Listening...';
                        document.getElementById('orb-status').textContent = '‚óâ READY';
                        document.getElementById('orb-status').className = 'orb-status ready';
                    }
                } else {
                    console.log("‚ö†Ô∏è Empty transcript - ignoring");
                    document.getElementById('live-transcript').textContent = 'üé§ Listening...';
                    document.getElementById('orb-status').textContent = '‚óâ READY';
                    document.getElementById('orb-status').className = 'orb-status ready';
                }
                
            } catch (e) {
                console.error("VAD audio processing error:", e);
                document.getElementById('live-transcript').textContent = '‚ùå Error - retrying...';
                
                // Resume listening after error
                setTimeout(() => {
                    if (voiceMode === 'continuous' && isRecording) {
                        document.getElementById('live-transcript').textContent = 'üé§ Listening...';
                    }
                }, 1000);
            }
            
            isProcessing = false;
        }
        
        // WAV Encoder for VAD audio (Float32 ‚Üí WAV)
        function encodeWAV(samples, sampleRate = 16000) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);
            
            // WAV header
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);           // Subchunk1Size
            view.setUint16(20, 1, true);            // AudioFormat (PCM)
            view.setUint16(22, 1, true);            // NumChannels (Mono)
            view.setUint32(24, sampleRate, true);   // SampleRate
            view.setUint32(28, sampleRate * 2, true); // ByteRate
            view.setUint16(32, 2, true);            // BlockAlign
            view.setUint16(34, 16, true);           // BitsPerSample
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length * 2, true);
            
            // Convert Float32 to Int16
            let offset = 44;
            for (let i = 0; i < samples.length; i++) {
                const s = Math.max(-1, Math.min(1, samples[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                offset += 2;
            }
            
            return buffer;
        }
        
        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
        
        // Override toggleRecording for voice mode support
        async function toggleRecording() {
            if (isProcessing || isSpeaking) return;
            
            if (voiceMode === 'continuous') {
                // VAD-based continuous mode
                if (isRecording) {
                    stopContinuousListening();
                } else {
                    await startContinuousListening();
                }
            } else {
                // Push-to-talk mode (original behavior)
                if (isRecording) {
                    stopRecording();
                } else {
                    await startRecording();
                }
            }
        }

        // ============================================
        // Image Handling for Vision
        // ============================================
        function handleImageForVision(file) {
            if (!file.type.startsWith('image/')) return;
            
            const reader = new FileReader();
            reader.onload = (e) => {
                currentImageData = e.target.result; // Full data URL
                
                // Show preview
                const previewContainer = document.getElementById('image-preview-container');
                const previewImg = document.getElementById('image-preview');
                previewImg.src = currentImageData;
                previewContainer.style.display = 'block';
                
                console.log('Image loaded for vision analysis');
            };
            reader.readAsDataURL(file);
        }
        
        function clearImagePreview() {
            currentImageData = null;
            document.getElementById('image-preview-container').style.display = 'none';
            document.getElementById('image-preview').src = '';
        }
        
        // Override handleFiles to support image vision
        const originalHandleFiles = handleFiles;
        function handleFiles(event) {
            const files = Array.from(event.target.files);
            
            // Check for images and load for vision
            const imageFile = files.find(f => f.type.startsWith('image/'));
            if (imageFile) {
                handleImageForVision(imageFile);
            }
            
            // Continue with original attachment handling
            files.forEach(file => {
                const attachment = {
                    name: file.name,
                    type: file.type,
                    size: file.size,
                    file: file
                };
                attachments.push(attachment);
            });

            renderAttachments();
            updateSendButton();
            event.target.value = '';
        }

        // ============================================
        // Utilities
        // ============================================
        function handleKeyPress(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendMessage();
            }
        }

        function autoResize(textarea) {
            textarea.style.height = 'auto';
            textarea.style.height = Math.min(textarea.scrollHeight, 120) + 'px';
        }

        function updateSendButton() {
            const btn = document.getElementById('send-btn');
            const input = document.getElementById('text-input');
            btn.disabled = isProcessing || (!input.value.trim() && attachments.length === 0);
        }

        function clearChat() {
            const container = document.getElementById('messages-container');
            container.innerHTML = '';
            addMessage('Chat cleared. How can I help you?', false);
            
            // Also clear on backend
            if (isConnected) {
                fetch(`${API_BASE}/clear`, { method: 'POST' }).catch(() => {});
            }
        }

        // Initialize
        document.getElementById('text-input').addEventListener('input', updateSendButton);

// ============================================
// Voice Selection Logic
// ============================================
let selectedVoice = "en_0"; // Default

function initVoiceList() {
    const select = document.getElementById('voice-select');
    const group = select.querySelector('optgroup[label="All Neural Voices"]');
    
    // Generate options for all 118 speakers
    for (let i = 0; i < 118; i++) {
        // Skip the ones we manually added in HTML to avoid duplicates
        if ([0, 1, 10, 21, 42].includes(i)) continue;
        
        const option = document.createElement('option');
        option.value = `en_${i}`;
        option.textContent = `Neural Speaker ${i}`;
        group.appendChild(option);
    }
}

function updateVoicePreference() {
    const select = document.getElementById('voice-select');
    selectedVoice = select.value;
    console.log("Voice changed to:", selectedVoice);
}

// Run this on load
window.addEventListener('DOMContentLoaded', initVoiceList);

        async function manualWebSearch() {
            const input = document.getElementById('text-input');
            const text = input.value.trim();

            if (!text) {
                alert("Please type a topic to search for first!");
                return;
            }

            // Visual feedback
            addMessage(`üåê Searching Google for: "${text}"`, true);
            input.value = '';
            
            // Force the search flag to true
            await getResponse(text, [], true); 
        }

        // ============================================
        // File Transcription
        // ============================================
        let transcribeFile = null;
        let transcriptData = null;

        function handleTranscribeFile(event) {
            const file = event.target.files[0];
            if (!file) return;
            
            transcribeFile = file;
            
            // Show file info
            document.getElementById('transcribe-upload-area').style.display = 'none';
            document.getElementById('transcribe-file-info').style.display = 'block';
            document.getElementById('transcribe-filename').textContent = file.name;
            document.getElementById('transcribe-filesize').textContent = formatFileSize(file.size);
            
            // Reset results
            document.getElementById('transcribe-results').style.display = 'none';
            document.getElementById('transcribe-progress').style.display = 'none';
        }

        function formatFileSize(bytes) {
            if (bytes < 1024) return bytes + ' B';
            if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB';
            return (bytes / (1024 * 1024)).toFixed(1) + ' MB';
        }

        function clearTranscribeFile() {
            transcribeFile = null;
            document.getElementById('transcribe-file-input').value = '';
            document.getElementById('transcribe-upload-area').style.display = 'block';
            document.getElementById('transcribe-file-info').style.display = 'none';
            document.getElementById('transcribe-results').style.display = 'none';
            document.getElementById('transcribe-progress').style.display = 'none';
        }

        async function startTranscription() {
            if (!transcribeFile) {
                alert('Please select a file first');
                return;
            }

            // UI Setup
            document.getElementById('transcribe-file-info').style.display = 'none';
            document.getElementById('transcribe-progress').style.display = 'block';
            document.getElementById('transcribe-results').style.display = 'none';
            
            // Progress Bar Setup
            const pBar = document.getElementById('real-progress-bar');
            const pText = document.getElementById('transcribe-progress-text');
            pBar.style.width = '0%';
            pBar.style.backgroundColor = ''; 
            pText.textContent = 'Uploading...';

            try {
                // 1. UPLOAD FILE & START JOB
                const formData = new FormData();
                formData.append('file', transcribeFile);
                
                const language = document.getElementById('transcribe-language').value;
                const uploadUrl = language 
                    ? `${API_BASE}/transcribe/file?language=${language}`
                    : `${API_BASE}/transcribe/file`;

                const uploadResponse = await fetch(uploadUrl, { method: 'POST', body: formData });

                if (!uploadResponse.ok) throw new Error("Upload failed. Check connection.");
                
                const uploadData = await uploadResponse.json();
                const jobId = uploadData.job_id;
                console.log(`Job Started: ${jobId}`);

                // 2. POLL FOR STATUS
                let pollInterval;
                let startTime = Date.now();
                
                pText.textContent = 'Processing on server... (You can close this tab, it will continue)';
                
                // Start a fake progress bar that moves slowly to 95%
                let fakeProgress = 5;
                const progressTimer = setInterval(() => {
                    if (fakeProgress < 95) {
                        fakeProgress += (95 - fakeProgress) / 50; // Slow down as it gets higher
                        pBar.style.width = `${fakeProgress}%`;
                    }
                }, 500);

                // Polling Loop
                const checkStatus = async () => {
                    try {
                        const statusResp = await fetch(`${API_BASE}/transcribe/status/${jobId}`);
                        if (!statusResp.ok) return; // Network blip, retry next time
                        
                        const statusData = await statusResp.json();
                        
                        if (statusData.status === 'completed') {
                            // DONE!
                            clearInterval(pollInterval);
                            clearInterval(progressTimer);
                            
                            pBar.style.width = '100%';
                            pText.textContent = 'Complete!';
                            transcriptData = statusData.result; // Store the result
                            
                            setTimeout(() => displayTranscriptResults(transcriptData), 500);
                            
                        } else if (statusData.status === 'failed') {
                            // FAILED
                            throw new Error(statusData.error || "Server processing failed");
                        } else {
                            // STILL PROCESSING
                            // Optional: Update text with elapsed time
                            const elapsed = Math.round((Date.now() - startTime) / 1000);
                            pText.textContent = `Processing on Titan V... (${elapsed}s)`;
                        }
                    } catch (e) {
                        clearInterval(pollInterval);
                        clearInterval(progressTimer);
                        handleError(e);
                    }
                };

                // Check every 2 seconds
                pollInterval = setInterval(checkStatus, 2000);

            } catch (error) {
                handleError(error);
            }
            
            function handleError(error) {
                console.error('Transcription error:', error);
                const pBar = document.getElementById('real-progress-bar');
                const pText = document.getElementById('transcribe-progress-text');
                
                pBar.style.width = '100%';
                pBar.style.backgroundColor = '#ff4444';
                pText.textContent = `Error: ${error.message}`;
                pText.style.color = '#ff4444';
                
                alert(`Transcription failed: ${error.message}`);
                
                setTimeout(() => {
                    document.getElementById('transcribe-progress').style.display = 'none';
                    document.getElementById('transcribe-file-info').style.display = 'block';
                    pText.style.color = '';
                }, 4000);
            }
        }

        function displayTranscriptResults(data) {
            document.getElementById('transcribe-progress').style.display = 'none';
            document.getElementById('transcribe-results').style.display = 'block';
            
            // Meta info
            const langNames = {
                'en': 'English', 'es': 'Spanish', 'fr': 'French', 'de': 'German',
                'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian', 'ja': 'Japanese',
                'ko': 'Korean', 'zh': 'Chinese'
            };
            document.getElementById('meta-language').textContent = `üåê ${langNames[data.language] || data.language}`;
            document.getElementById('meta-duration').textContent = `‚è±Ô∏è ${formatDuration(data.duration)}`;
            document.getElementById('meta-time').textContent = `‚ö° ${data.processing_time}s`;
            
            // Transcript text
            document.getElementById('transcribe-text').textContent = data.transcript;
            
            // Segments with timestamps
            const segmentsDiv = document.getElementById('transcribe-segments');
            if (data.segments && data.segments.length > 0) {
                segmentsDiv.innerHTML = data.segments.map(seg => `
                    <div class="segment-item">
                        <span class="segment-time">[${formatTime(seg.start)} ‚Üí ${formatTime(seg.end)}]</span>
                        <span class="segment-text">${seg.text}</span>
                    </div>
                `).join('');
            } else {
                segmentsDiv.innerHTML = '<p style="color: var(--text-dim);">No timestamp segments available</p>';
            }
        }

        function formatDuration(seconds) {
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return `${mins}:${secs.toString().padStart(2, '0')}`;
        }

        function formatTime(seconds) {
            const mins = Math.floor(seconds / 60);
            const secs = (seconds % 60).toFixed(1);
            return `${mins}:${secs.padStart(4, '0')}`;
        }

        function copyTranscript() {
            if (!transcriptData) return;
            
            navigator.clipboard.writeText(transcriptData.transcript).then(() => {
                // Brief visual feedback
                const btn = event.target;
                const originalText = btn.textContent;
                btn.textContent = '‚úì Copied!';
                btn.style.background = 'var(--primary)';
                btn.style.color = 'black';
                setTimeout(() => {
                    btn.textContent = originalText;
                    btn.style.background = '';
                    btn.style.color = '';
                }, 2000);
            });
        }

        function downloadTranscript() {
            if (!transcriptData) return;
            
            // Create text file with transcript and metadata
            let content = `# Transcription\n`;
            content += `File: ${transcribeFile?.name || 'Unknown'}\n`;
            content += `Language: ${transcriptData.language}\n`;
            content += `Duration: ${formatDuration(transcriptData.duration)}\n`;
            content += `Processing Time: ${transcriptData.processing_time}s\n`;
            content += `\n---\n\n`;
            content += transcriptData.transcript;
            
            if (transcriptData.segments && transcriptData.segments.length > 0) {
                content += `\n\n---\n\n# Timestamps\n\n`;
                transcriptData.segments.forEach(seg => {
                    content += `[${formatTime(seg.start)} ‚Üí ${formatTime(seg.end)}] ${seg.text}\n`;
                });
            }
            
            const blob = new Blob([content], { type: 'text/plain' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `transcript_${transcribeFile?.name?.replace(/\.[^.]+$/, '') || 'output'}.txt`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }

        function newTranscription() {
            clearTranscribeFile();
            transcriptData = null;
        }

        // Drag and drop support for transcribe upload
        document.addEventListener('DOMContentLoaded', () => {
            const uploadArea = document.getElementById('transcribe-upload-area');
            if (uploadArea) {
                uploadArea.addEventListener('dragover', (e) => {
                    e.preventDefault();
                    uploadArea.classList.add('dragover');
                });
                
                uploadArea.addEventListener('dragleave', () => {
                    uploadArea.classList.remove('dragover');
                });
                
                uploadArea.addEventListener('drop', (e) => {
                    e.preventDefault();
                    uploadArea.classList.remove('dragover');
                    
                    const file = e.dataTransfer.files[0];
                    if (file) {
                        // Validate file type
                        const validTypes = ['.mp3', '.mp4', '.m4a', '.wav', '.flac', '.ogg', '.webm', '.avi', '.mkv', '.mov', '.aac', '.wma'];
                        const ext = '.' + file.name.split('.').pop().toLowerCase();
                        
                        if (validTypes.includes(ext)) {
                            transcribeFile = file;
                            document.getElementById('transcribe-upload-area').style.display = 'none';
                            document.getElementById('transcribe-file-info').style.display = 'block';
                            document.getElementById('transcribe-filename').textContent = file.name;
                            document.getElementById('transcribe-filesize').textContent = formatFileSize(file.size);
                        } else {
                            alert(`Unsupported file type: ${ext}\n\nSupported: ${validTypes.join(', ')}`);
                        }
                    }
                });
            }
        });

    </script>
</body>
</html>
