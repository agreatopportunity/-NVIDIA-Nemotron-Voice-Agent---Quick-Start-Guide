# ğŸ¤– Nemotron AI Voice Assistant v3.2 (vLLM Enhanced)

A **high-performance, self-hosted AI voice assistant** powered by **NVIDIA Nemotron** models, featuring:

* ğŸš€ **vLLM** for fast, low-latency LLM inference (async streaming when available)
* ğŸ”Š **NVIDIA NeMo FastPitch + HiFi-GAN** for ultra-low latency, high-quality speech synthesis
* ğŸ¤ Real-time ASR with Nemotron Streaming Speech
* ğŸ‘ï¸ Vision understanding with BLIP
* ğŸŒ Optional live web search (Google Custom Search)
* ğŸŒ¤ï¸ Context-aware weather & time
* ğŸ§  Optional â€œDeep Thinkâ€ mode with separate reasoning display
* âš¡ Optimized for **dual-GPU** setups (Ada + Volta)

Designed for **local execution**, **full control**, and **maximum performance**.

---

## âœ¨ Key Features

| Feature                         | Description                                               |
| ------------------------------- | --------------------------------------------------------- |
| ğŸ¨ **Matrix-style Web UI**      | Animated cyber-themed interface                           |
| ğŸ¤ **Voice Input**              | Push-to-talk or continuous listening                      |
| ğŸ—£ï¸ **Streaming Voice Output**  | Sentence-level TTS while the model is still thinking      |
| ğŸ§  **Deep Think Mode**          | Displays internal reasoning separately from spoken answer |
| ğŸš€ **vLLM Backend**             | Fast decoding, async streaming, HF fallback               |
| ğŸ”Š **NeMo TTS**                 | FastPitch + HiFi-GAN (Silero fallback)                    |
| ğŸ‘ï¸ **Vision / Image Analysis** | BLIP image captioning                                     |
| ğŸŒ **Live Web Search**          | Google Custom Search (robust retries & caching)           |
| ğŸŒ¤ï¸ **Weather Awareness**       | OpenWeather API                                           |
| ğŸ“Š **Performance Metrics**      | Live latency stats via `/metrics`                         |
| âš¡ **Multi-GPU Optimized**       | Separate GPUs for realtime vs batch tasks                 |

---

## ğŸ–¥ï¸ Hardware Requirements

### Minimum

| Component | Requirement                    |
| --------- | ------------------------------ |
| GPU       | NVIDIA GPU with **12GB+ VRAM** |
| RAM       | 16GB                           |
| Python    | 3.10+                          |
| CUDA      | 12.x                           |
| Driver    | 550.x recommended              |

### Recommended (Dual GPU)

| Component                    | Purpose                    |
| ---------------------------- | -------------------------- |
| **GPU 0 â€“ RTX 4060 Ti 16GB** | ASR, LLM, TTS, Vision      |
| **GPU 1 â€“ TITAN V 12GB**     | Whisper file transcription |
| CPU                          | Modern 8â€“16 core           |
| RAM                          | 64GB                       |
| CUDA                         | 12.4                       |
| Driver                       | 550.120                    |

### Approximate VRAM Usage

```
GPU 0 (RTX 4060 Ti):
- Nemotron ASR (0.6B)        ~1.2 GB
- Nemotron LLM (9B)          ~6â€“8 GB (vLLM dependent)
- NeMo FastPitch + HiFi-GAN  ~0.5 GB
- BLIP Vision                ~1.0 GB
- CUDA overhead              ~1.0 GB
------------------------------------
Total                         ~9â€“11 GB

GPU 1 (TITAN V):
- Whisper large-v3           ~3.0 GB
```

---

## ğŸ§  Model Stack

| Component     | Model                                      | Purpose                       |
| ------------- | ------------------------------------------ | ----------------------------- |
| ASR           | `nvidia/nemotron-speech-streaming-en-0.6b` | Real-time speech-to-text      |
| LLM           | `nvidia/NVIDIA-Nemotron-Nano-9B-v2`        | Language reasoning & response |
| LLM Backend   | **vLLM** (preferred)                       | Fast inference + streaming    |
| Fallback LLM  | HF Transformers (4-bit NF4)                | Compatibility fallback        |
| TTS           | NeMo FastPitch + HiFi-GAN                  | Fast, high-quality speech     |
| Vision        | BLIP                                       | Image captioning              |
| Transcription | Whisper large-v3                           | File & video transcription    |

---

## ğŸ§© System Architecture (High-Level)

```
Browser / UI
   â”‚
   â–¼
FastAPI Server (Uvicorn)
   â”œâ”€ ASR (Nemotron Streaming)
   â”œâ”€ LLM (vLLM async â†’ HF fallback)
   â”œâ”€ THINK extraction
   â”œâ”€ Sentence streaming
   â”œâ”€ NeMo TTS (FastPitch + HiFi-GAN)
   â”œâ”€ Vision (BLIP)
   â”œâ”€ Whisper (GPU1)
   â”œâ”€ Web Search (Google CSE)
   â””â”€ Metrics (/metrics)
```

---

## ğŸ“¦ Installation

### 1. Python & CUDA

```bash
pip install torch torchvision torchaudio \
  --index-url https://download.pytorch.org/whl/cu124
```

### 2. Core Dependencies

```bash
pip install fastapi uvicorn python-multipart websockets httpx aiofiles python-dotenv
pip install accelerate bitsandbytes
pip install "nemo_toolkit[asr,tts]"
pip install openai-whisper
pip install soundfile librosa
pip install vllm
pip install causal-conv1d --no-build-isolation --no-cache-dir
pip install mamba-ssm --no-build-isolation --no-cache-dir
```

> âš ï¸ If NeMo TTS pulls extra deps, follow NeMoâ€™s official install guide for your OS.

---

## ğŸ” Environment Variables

Create `.env`:

```bash
OPENWEATHER_API_KEY=your_key_here
GOOGLE_API_KEY=your_google_api_key
GOOGLE_CSE_ID=your_custom_search_id
```

All APIs are optional. The system runs fully offline without them.

---

## ğŸš€ Quick Start

```bash
python nemotron_web_server_vllm.py --host 0.0.0.0 --port 5050
```

### Optional Flags

```bash
# Disable vLLM (force HF fallback)
python nemotron_web_server_vllm.py --no-vllm

# Disable torch.compile (recommended for 4-bit fallback)
python nemotron_web_server_vllm.py --no-compile

# Hot reload for development
python nemotron_web_server_vllm.py --reload
```

---

## ğŸŒ Access Points

| URL                | Description                |
| ------------------ | -------------------------- |
| `/health`          | Server status              |
| `/metrics`         | Performance metrics        |
| `/chat`            | Text chat                  |
| `/chat/speak`      | Chat with TTS audio        |
| `/transcribe`      | Quick ASR                  |
| `/transcribe/file` | Whisper file transcription |
| `/ws/voice/stream` | Real-time streaming voice  |

---

## ğŸ¤ Voice Interaction

### Push-to-Talk

1. Click **Record**
2. Speak
3. Release â†’ auto submit
4. AI responds with voice

### Streaming Mode (WebSocket)

* Tokens stream in real time
* Audio plays sentence-by-sentence
* Final response synthesized at completion

---

## ğŸ‘ï¸ Vision / Image Analysis

Upload or attach an image and ask:

> â€œWhatâ€™s in this image?â€

The BLIP model analyzes and responds naturally.

---

## ğŸ§ File Transcription (Whisper)

```bash
curl -X POST http://localhost:5050/transcribe/file \
  -F "file=@meeting.mp4"
```

Response:

```json
{
  "text": "Full transcription text..."
}
```

---

## âš¡ Performance Notes

| Optimization         | Effect                                    |
| -------------------- | ----------------------------------------- |
| vLLM                 | Major latency reduction                   |
| Reduced think tokens | Faster Deep Think                         |
| Streaming TTS        | Near-instant speech                       |
| Robust HTTP retries  | No more search timeouts                   |
| torch.compile        | Disabled by default (hurts 4-bit latency) |

> First request is always slower due to CUDA warm-up.

---

## ğŸ“ Project Structure

```
speechAi/
â”œâ”€â”€ nemotron_web_server_vllm.py   # Main server (v3.2)
â”œâ”€â”€ nemotron_web_server.py        # Legacy backup
â”œâ”€â”€ nemotron_web_ui.html          # Web UI
â”œâ”€â”€ sw.js                         # PWA service worker
â”œâ”€â”€ README.md
â”œâ”€â”€ .env
â””â”€â”€ static/
```

---

## ğŸ› Troubleshooting

| Issue               | Fix                       |
| ------------------- | ------------------------- |
| Slow first response | Normal CUDA warmup        |
| Out of VRAM         | Reduce `max_tokens_fast`  |
| vLLM load fails     | Use `--no-vllm`           |
| TTS errors          | Silero fallback auto-used |
| Google timeouts     | API quota / network       |

---

## ğŸ“„ License

MIT License

---

## ğŸ™Œ Credits

* **NVIDIA Nemotron & NeMo** â€” NVIDIA
* **vLLM** â€” UC Berkeley / community
* **Whisper** â€” OpenAI
* **BLIP** â€” Salesforce Research
* **FastAPI** â€” SebastiÃ¡n RamÃ­rez

---

<p align="center">
<b>Built for people who want AI on their own hardware.</b><br>
<i>Your AI â€¢ Your GPUs â€¢ Your Control</i>
</p>


